{"name":"ensmlp","tagline":"MATLAB Code for Variational Learning of Neural Networks","body":"Variational Learning in Neural Networks\r\n=======================================\r\n\r\nThis page describes examples of how to use ensemble learning in neural\r\nnetworks software (ENSMLP). The software includes variational\r\napproximations that are Gaussian and mixtures of Gaussians used to\r\napproximate neural network posterior distributions. RELEASEINFORMATION\r\n\r\nFirst release in response to a request for the code. Code was written in\r\n1998-1999 but is being released for first time in 2007. The code is\r\nheavily based on the NETLAB toolbox, to such an extent that copyright\r\nfrom NETLAB probably applies to large portions of this software. Please\r\nsee GPL licenses on that software for details of the implications of\r\nthis.\r\n\r\nExamples\r\n--------\r\n\r\n### Tecator Data\r\n\r\nThe ensemble learning is demonstrated with a series of examples on the\r\n['Tecator'](http://lib.stat.cmu.edu/datasets/tecator) data of Thodberg.\r\n\r\nThere are several different configurations of the models to run on the\r\nTecator data, all start with '`dem`'. I've put together this code\r\nrelease over a couple of days, and haven't managed to recreate exactly\r\nthe results on this data we quote in our original tech report. Be aware\r\nalso that the scripts each take a few hours to run. Finally the\r\n`demTecatorMixEns...` scripts can only be run once the corresponding\r\n`demTecatorEns...` script has been run.\r\n\r\nFinally there is a Gaussian process demo, `demTecatorGpRbfArd` that you\r\nwill need to download my [GP toolbox](../gp/) to run.\r\n","google":"UA-62968536-1","note":"Don't delete this file! It's used internally to help with page regeneration."}